{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whenever we want to have full control over the save and restore process, the best way is to build our own functions manually.\n",
    "\n",
    "#### The following script shows an example of manually saving and restoring objects using JSON. This approach allows us to select the data which needs to be saved, such as the model parameters, coefficients, training data, and anything else we need.\n",
    "\n",
    "#### For simplicity, we'll save only three model parameters and the training data. Some additional data we could store with this approach is, for example, a cross-validation score on the training set, test data, accuracy score on the test data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "import json  \n",
    "import numpy as np\n",
    "\n",
    "# Import the Logistic Regression Module from Scikit Learn\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "\n",
    "# Import the IRIS Dataset to be used in this Kernel\n",
    "from sklearn.datasets import load_iris  \n",
    "\n",
    "# Load the Module to split the Dataset into Train & Test \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "Iris_data = load_iris() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(Iris_data.data, \n",
    "                                                Iris_data.target, \n",
    "                                                test_size=0.3, \n",
    "                                                random_state=4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we want to save all of this data in a single object, one possible way to do it is to create a new class which inherits from the model class, which in our example is LogisticRegression. \n",
    "\n",
    "#### The new class, called MyLogReg, then implements the methods save_json and load_json for saving and restoring to/from a JSON file, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogReg(LogisticRegression):\n",
    "\n",
    "    # Override the class constructor\n",
    "    def __init__(self, C=1.0, solver='liblinear', max_iter=100, X_train=None, Y_train=None):\n",
    "        LogisticRegression.__init__(self, C=C, solver=solver, max_iter=max_iter)\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "\n",
    "    # A method for saving object data to JSON file\n",
    "    def save_json(self, filepath):\n",
    "        dict_ = {}\n",
    "        dict_['C'] = self.C\n",
    "        dict_['max_iter'] = self.max_iter\n",
    "        dict_['solver'] = self.solver\n",
    "        dict_['X_train'] = self.X_train.tolist() if self.X_train is not None else 'None'\n",
    "        dict_['Y_train'] = self.Y_train.tolist() if self.Y_train is not None else 'None'\n",
    "\n",
    "        # Creat json and save to file\n",
    "        json_txt = json.dumps(dict_, indent=4)\n",
    "        with open(filepath, 'w') as file:\n",
    "            file.write(json_txt)\n",
    "\n",
    "    # A method for loading data from JSON file\n",
    "    def load_json(self, filepath):\n",
    "        with open(filepath, 'r') as file:\n",
    "            dict_ = json.load(file)\n",
    "\n",
    "        self.C = dict_['C']\n",
    "        self.max_iter = dict_['max_iter']\n",
    "        self.solver = dict_['solver']\n",
    "        self.X_train = np.asarray(dict_['X_train']) if dict_['X_train'] != 'None' else None\n",
    "        self.Y_train = np.asarray(dict_['Y_train']) if dict_['Y_train'] != 'None' else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we create an object mylogreg, pass the training data to it, and save it to file.\n",
    "\n",
    "#### Then we create a new object json_mylogreg and call the load_json method to load the data from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLogReg(C=1.0,\n",
       "     X_train=array([[4.3, 3. , 1.1, 0.1],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       ...,\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.7, 2.8, 6.7, 2. ]]),\n",
       "     Y_train=array([0, 0, ..., 2, 2]), max_iter=100, solver='liblinear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"mylogreg.json\"\n",
    "\n",
    "# Create a model and train it\n",
    "mylogreg = MyLogReg(X_train=Xtrain, Y_train=Ytrain)  \n",
    "mylogreg.save_json(filepath)\n",
    "\n",
    "# Create a new object and load its data from JSON file\n",
    "json_mylogreg = MyLogReg()  \n",
    "json_mylogreg.load_json(filepath)  \n",
    "json_mylogreg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
