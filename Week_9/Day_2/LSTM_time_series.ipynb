{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Close</th>\n",
       "      <th>Total Trade Quantity</th>\n",
       "      <th>Turnover (Lacs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>220.10</td>\n",
       "      <td>221.25</td>\n",
       "      <td>217.05</td>\n",
       "      <td>219.55</td>\n",
       "      <td>219.80</td>\n",
       "      <td>2171956</td>\n",
       "      <td>4771.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>221.10</td>\n",
       "      <td>222.20</td>\n",
       "      <td>214.75</td>\n",
       "      <td>219.55</td>\n",
       "      <td>218.30</td>\n",
       "      <td>1416279</td>\n",
       "      <td>3092.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-22</td>\n",
       "      <td>229.45</td>\n",
       "      <td>231.60</td>\n",
       "      <td>222.00</td>\n",
       "      <td>223.05</td>\n",
       "      <td>223.25</td>\n",
       "      <td>3529711</td>\n",
       "      <td>8028.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>230.30</td>\n",
       "      <td>232.70</td>\n",
       "      <td>225.50</td>\n",
       "      <td>227.75</td>\n",
       "      <td>227.20</td>\n",
       "      <td>1527904</td>\n",
       "      <td>3490.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>237.70</td>\n",
       "      <td>240.80</td>\n",
       "      <td>229.45</td>\n",
       "      <td>231.30</td>\n",
       "      <td>231.10</td>\n",
       "      <td>2945914</td>\n",
       "      <td>6961.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>237.10</td>\n",
       "      <td>237.70</td>\n",
       "      <td>233.05</td>\n",
       "      <td>234.40</td>\n",
       "      <td>235.45</td>\n",
       "      <td>1723113</td>\n",
       "      <td>4052.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-10-15</td>\n",
       "      <td>229.70</td>\n",
       "      <td>237.00</td>\n",
       "      <td>226.80</td>\n",
       "      <td>234.80</td>\n",
       "      <td>234.90</td>\n",
       "      <td>1224339</td>\n",
       "      <td>2845.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>226.25</td>\n",
       "      <td>232.35</td>\n",
       "      <td>225.50</td>\n",
       "      <td>228.70</td>\n",
       "      <td>229.10</td>\n",
       "      <td>1165527</td>\n",
       "      <td>2675.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>215.00</td>\n",
       "      <td>229.70</td>\n",
       "      <td>215.00</td>\n",
       "      <td>225.60</td>\n",
       "      <td>224.60</td>\n",
       "      <td>1293881</td>\n",
       "      <td>2890.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>215.00</td>\n",
       "      <td>229.65</td>\n",
       "      <td>215.00</td>\n",
       "      <td>228.25</td>\n",
       "      <td>228.40</td>\n",
       "      <td>2919278</td>\n",
       "      <td>6557.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>215.50</td>\n",
       "      <td>219.15</td>\n",
       "      <td>209.60</td>\n",
       "      <td>215.00</td>\n",
       "      <td>216.50</td>\n",
       "      <td>1844462</td>\n",
       "      <td>3940.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>208.00</td>\n",
       "      <td>222.25</td>\n",
       "      <td>206.85</td>\n",
       "      <td>216.00</td>\n",
       "      <td>215.15</td>\n",
       "      <td>4642146</td>\n",
       "      <td>10062.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>217.00</td>\n",
       "      <td>218.60</td>\n",
       "      <td>205.90</td>\n",
       "      <td>210.25</td>\n",
       "      <td>209.20</td>\n",
       "      <td>3519515</td>\n",
       "      <td>7407.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>223.50</td>\n",
       "      <td>227.80</td>\n",
       "      <td>216.15</td>\n",
       "      <td>217.25</td>\n",
       "      <td>218.20</td>\n",
       "      <td>1728786</td>\n",
       "      <td>3815.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>230.00</td>\n",
       "      <td>237.50</td>\n",
       "      <td>225.75</td>\n",
       "      <td>226.45</td>\n",
       "      <td>227.60</td>\n",
       "      <td>1708590</td>\n",
       "      <td>3960.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>234.55</td>\n",
       "      <td>234.60</td>\n",
       "      <td>221.05</td>\n",
       "      <td>230.30</td>\n",
       "      <td>230.90</td>\n",
       "      <td>1534749</td>\n",
       "      <td>3486.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date    Open    High     Low    Last   Close  Total Trade Quantity  \\\n",
       "0   2018-10-24  220.10  221.25  217.05  219.55  219.80               2171956   \n",
       "1   2018-10-23  221.10  222.20  214.75  219.55  218.30               1416279   \n",
       "2   2018-10-22  229.45  231.60  222.00  223.05  223.25               3529711   \n",
       "3   2018-10-19  230.30  232.70  225.50  227.75  227.20               1527904   \n",
       "4   2018-10-17  237.70  240.80  229.45  231.30  231.10               2945914   \n",
       "5   2018-10-16  237.10  237.70  233.05  234.40  235.45               1723113   \n",
       "6   2018-10-15  229.70  237.00  226.80  234.80  234.90               1224339   \n",
       "7   2018-10-12  226.25  232.35  225.50  228.70  229.10               1165527   \n",
       "8   2018-10-11  215.00  229.70  215.00  225.60  224.60               1293881   \n",
       "9   2018-10-10  215.00  229.65  215.00  228.25  228.40               2919278   \n",
       "10  2018-10-09  215.50  219.15  209.60  215.00  216.50               1844462   \n",
       "11  2018-10-08  208.00  222.25  206.85  216.00  215.15               4642146   \n",
       "12  2018-10-05  217.00  218.60  205.90  210.25  209.20               3519515   \n",
       "13  2018-10-04  223.50  227.80  216.15  217.25  218.20               1728786   \n",
       "14  2018-10-03  230.00  237.50  225.75  226.45  227.60               1708590   \n",
       "15  2018-10-01  234.55  234.60  221.05  230.30  230.90               1534749   \n",
       "\n",
       "    Turnover (Lacs)  \n",
       "0           4771.34  \n",
       "1           3092.15  \n",
       "2           8028.37  \n",
       "3           3490.78  \n",
       "4           6961.65  \n",
       "5           4052.25  \n",
       "6           2845.68  \n",
       "7           2675.91  \n",
       "8           2890.85  \n",
       "9           6557.95  \n",
       "10          3940.70  \n",
       "11         10062.83  \n",
       "12          7407.06  \n",
       "13          3815.79  \n",
       "14          3960.27  \n",
       "15          3486.05  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = pd.read_csv('tataglobal.csv', header= 0)\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[220.1 ],\n",
       "       [221.1 ],\n",
       "       [229.45],\n",
       "       [230.3 ],\n",
       "       [237.7 ],\n",
       "       [237.1 ],\n",
       "       [229.7 ],\n",
       "       [226.25],\n",
       "       [215.  ],\n",
       "       [215.  ],\n",
       "       [215.5 ],\n",
       "       [208.  ],\n",
       "       [217.  ],\n",
       "       [223.5 ],\n",
       "       [230.  ],\n",
       "       [234.55]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40740741],\n",
       "       [0.44107744],\n",
       "       [0.72222222],\n",
       "       [0.75084175],\n",
       "       [1.        ],\n",
       "       [0.97979798],\n",
       "       [0.73063973],\n",
       "       [0.61447811],\n",
       "       [0.23569024],\n",
       "       [0.23569024],\n",
       "       [0.25252525],\n",
       "       [0.        ],\n",
       "       [0.3030303 ],\n",
       "       [0.52188552],\n",
       "       [0.74074074],\n",
       "       [0.89393939]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data with Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1975"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(60, 2035):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e4d1dc890319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
